{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter Optimization using Talos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Necessary modules for the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the plaidml backend\n",
    "import plaidml.keras\n",
    "plaidml.keras.install_backend()\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import RMSprop\n",
    "import talos as ta\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "%matplotlib inline\n",
    "num_classes = 10\n",
    "batch_size = 128\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data and splitting into training and test data \n",
    "\n",
    "#### The training data and test data is returned by the load data function from mnist. The number of training and test data are 60000\n",
    "\n",
    "#### and 10000 respectively. These are stored in the variables 'x_training' and 'x_test'. The function load data returns two tuples of\n",
    "\n",
    "#### arrays which are three dimensional numpy arrays of size (60000, 28, 28), 60000, (10000,28,28) and 10000. We will reshape these \n",
    "\n",
    "#### variables into our desired shape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data is returned as a tuple of numpy arrays(data) which has a shape: x_training(60000,28,28),x_test(10000,28,28)\n",
    "(x_training,y_training),(x_test, y_test) = mnist.load_data() \n",
    "\n",
    "# the shape of the array is converted as a two dimensional array of shape: x_training(60000,784),x_test(10000,784)\n",
    "x_training = x_training.reshape(60000,784)\n",
    "x_test = x_test.reshape(10000,784)\n",
    "\n",
    "# The greyscale values range from 0 to 255 integers. We are interested in converting it into values between 0 and 1. \n",
    "x_training = x_training.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_training /= 255\n",
    "x_test /= 255\n",
    "print(x_training.shape[0], 'training sets')\n",
    "print(x_test.shape[0], 'test sets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting class vectors in binary class matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_training = keras.utils.to_categorical(y_training, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the keras neural network model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mnist_model(x_training, y_training, x_test, y_test, params):\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(params['first_neurons'], activation = 'relu', input_shape = (784,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512, activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_classes, activation = 'softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer = RMSprop(), \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "    history = model.fit(x_training, y_training, \n",
    "                    batch_size = params['batch_size'], \n",
    "                    epochs = params['epochs'], \n",
    "                    verbose = 1,\n",
    "                    #callbacks = [PlotLossesKeras()],\n",
    "                    validation_data = (x_test, y_test), shuffle = True)\n",
    "\n",
    "    return history, model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the parameter Space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'first_neurons':[10,50,100,200,300,500,1000],\n",
    "     'epochs': [50],\n",
    "     'batch_size':[30]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = ta.Scan(x_training, y_training,\n",
    "           params = p, model = mnist_model,\n",
    "           dataset_name = 'mnist',\n",
    "           experiment_no = '1',\n",
    "            save_best_model = True,\n",
    "            shuffle = True,\n",
    "            search_method = 'random')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
